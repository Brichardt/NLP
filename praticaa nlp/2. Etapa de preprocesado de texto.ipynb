{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LERt57HkImhd"
      },
      "source": [
        "# Práctica de NLP & Searching"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Etapa de preprocesado de texto**\n"
      ],
      "metadata": {
        "id": "HEMRFDAlsHr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta sección se centra en la preparación de los datos textuales para su posterior análisis, especialmente para el análisis de sentimientos. Esta etapa crucial, denominada preprocesamiento, tiene como objetivo limpiar y normalizar los datos textuales para mejorar el rendimiento de los modelos de aprendizaje automático. En esta parte, aplicaremos diferentes técnicas de preprocesamiento a las reseñas de productos de la categoría \"Digital Music\", utilizando la biblioteca NLTK y el lenguaje de programación Python."
      ],
      "metadata": {
        "id": "cial55N-yzDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your data is in 'Digital_Music.jsonl'\n",
        "corpus_hcpc = pd.read_json('Digital_Music.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "wRfuoJ5MriMi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código prepara los datos textuales para el análisis de sentimientos limpiando y normalizando el texto de las reseñas de productos.\n",
        "\n",
        "En resumen:\n",
        "\n",
        "El código importa las librerías necesarias (pandas, nltk, re).\n",
        "Descarga los recursos de NLTK para el procesamiento del lenguaje natural.\n",
        "Carga los datos de las reseñas en un DataFrame de pandas.\n",
        "Define funciones para limpiar y normalizar el texto (eliminación de palabras vacías, puntuación y lematización).\n",
        "Combina los títulos y los textos de las reseñas.\n",
        "Aplica las funciones de preprocesamiento para crear una nueva columna con el texto limpio, listo para el análisis de sentimientos."
      ],
      "metadata": {
        "id": "3g6CcpTY0Qm3"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# Descarga de los datos necesarios de NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet') # Para la lematización\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Carga de los datos\n",
        "corpus_hcpc = pd.read_json('Digital_Music.jsonl', lines=True)\n",
        "\n",
        "# Definición de las funciones de preprocesamiento\n",
        "def eliminar_stopwords(tokens, idioma='english'):\n",
        "    stop_words = set(stopwords.words(idioma))\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "def eliminar_puntuacion(texto):\n",
        "    return re.sub(r'[^\\w\\s]', '', texto)\n",
        "\n",
        "def lematizar_tokens(tokens):\n",
        "    lematizador = WordNetLemmatizer()\n",
        "    return [lematizador.lemmatize(token) for token in tokens]\n",
        "\n",
        "def preprocesar_texto(texto):\n",
        "    \"\"\"Preprocesa el texto de una reseña.\"\"\"\n",
        "    texto = texto.lower()  # Convertir a minúsculas\n",
        "    texto = eliminar_puntuacion(texto)  # Eliminar puntuación\n",
        "    tokens = word_tokenize(texto)  # Tokenizar\n",
        "    tokens = eliminar_stopwords(tokens)  # Eliminar stopwords\n",
        "    tokens = lematizar_tokens(tokens)  # Lematizar\n",
        "    texto_preprocesado = \" \".join(tokens)  # Reconstruir el texto\n",
        "    return texto_preprocesado\n",
        "\n",
        "# Creación de la columna 'texto_titulo' y aplicación del preprocesamiento\n",
        "if 'texto_titulo' not in corpus_hcpc.columns:\n",
        "    corpus_hcpc[\"texto_titulo\"] = corpus_hcpc[\"title\"] + \" \" + corpus_hcpc[\"text\"]\n",
        "\n",
        "corpus_hcpc['texto_preprocesado'] = corpus_hcpc['texto_titulo'].apply(preprocesar_texto)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvRIhxprxm7G",
        "outputId": "9eb267f1-5c5e-4de4-cbae-b26aaa42ccf3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En conclusión se ha realizado un preprocesamiento completo de los datos textuales de las reseñas de productos. Utilizando técnicas como la eliminación de stopwords, la eliminación de puntuación y la lematización, hemos limpiado y normalizado el texto, haciéndolo más adecuado para el análisis de sentimientos. La modularidad del código se ha garantizado mediante el uso de funciones anidadas, lo que facilita su comprensión y mantenimiento. Los datos preprocesados ahora se almacenan en una nueva columna del DataFrame corpus_hcpc, listos para ser utilizados en la siguiente etapa del análisis. Este preprocesamiento es fundamental para mejorar la calidad y la fiabilidad de los resultados del análisis de sentimientos.\n",
        "\n",
        "Puntos clave a recordar:\n",
        "\n",
        "Objetivo: Preparar los datos textuales para el análisis de sentimientos.\n",
        "Técnicas utilizadas: Eliminación de stopwords, eliminación de puntuación, lematización.\n",
        "Modularidad: Funciones anidadas para una mejor organización del código.\n",
        "Resultado: Datos textuales limpios y normalizados, almacenados en una nueva columna del DataFrame.\n",
        "Importancia: Mejora la calidad y la fiabilidad del análisis de sentimientos."
      ],
      "metadata": {
        "id": "RwRjYDvlzERq"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}